{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/geli/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414113\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "##---- Porter Stemmer---#\n",
    "stemmer_ps = PorterStemmer()\n",
    "\n",
    "def sentenceStemmerPS(sentence):\n",
    "    # we need to tokenize the sentence or else stemming will return the entire sentence as is.\n",
    "    token_words = word_tokenize(sentence)\n",
    "    stem_sentence = []\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(stemmer_ps.stem(word))\n",
    "        # adding a space so that we can join all the words at the end to form the sentence again.\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "####---Lemmatizer----#\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def sentenceLemmatizer(sentence):\n",
    "    token_words = word_tokenize(sentence)\n",
    "# we need to tokenize the sentence or else lemmatizing will return the entire sentence as is.\n",
    "    lemma_sentence = []\n",
    "    for word in token_words:\n",
    "        lemma_sentence.append(lemmatizer.lemmatize(word))\n",
    "        lemma_sentence.append(\" \")\n",
    "    return \"\".join(lemma_sentence)\n",
    "\n",
    "captions_dir = 'dataset/captions_train2014.json'\n",
    "caption_dataset = json.load(open(captions_dir,'r'))\n",
    "print(len(caption_dataset['annotations']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "captionList = []\n",
    "imageidList = []\n",
    "captionSentList= []\n",
    "stop_words = ['.']\n",
    "stopwords_dir='./dataset/stopwords_en.txt'\n",
    "if stopwords_dir:\n",
    "    with open((stopwords_dir), \"r\") as data:\n",
    "        for word in data:\n",
    "            stop_words.append(word.strip())\n",
    "\n",
    "for annotation in caption_dataset['annotations'][:100]:\n",
    "    caption = annotation['caption'].lower()\n",
    "    caption_lemmatized = sentenceLemmatizer(caption)\n",
    "    # caption_without_sw = [word for word in word_tokenize(caption) if not word in stopwords.words('english')]\n",
    "    caption_without_sw = [word for word in word_tokenize(caption_lemmatized) if not word in stop_words]\n",
    "\n",
    "    captionList.append(caption_without_sw)\n",
    "    captionSentList.append(' '.join(caption_without_sw))\n",
    "    \n",
    "    imageidList.append(annotation['image_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 28231,\n",
       " 'id': 3183,\n",
       " 'caption': 'A blurry bike rider zooms past a new Mercedes. '}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf processing\n"
     ]
    }
   ],
   "source": [
    "tfidf = 4\n",
    "n = tfidf\n",
    "words, weight = None, None\n",
    "if n > 0:\n",
    "    print(\"tf-idf processing\")\n",
    "    vectorizer = CountVectorizer()\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(captionSentList))\n",
    "    words = vectorizer.get_feature_names() \n",
    "    weight = tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap2ids={}\n",
    "num_img = 5\n",
    "for idx, cap in enumerate(captionList):\n",
    "    imageID = imageidList[idx]\n",
    "    if n > 0:\n",
    "        w = weight[idx]\n",
    "        loc = np.argsort(-w)\n",
    "        top_words = []\n",
    "        for i in range(n):\n",
    "            if w[loc[i]] > 0.0:\n",
    "                top_words.append(words[loc[i]])\n",
    "        top_cap = []\n",
    "        for word in cap:\n",
    "            if word.lower() in top_words:\n",
    "                top_cap.append(word)\n",
    "\n",
    "    for word in top_cap:\n",
    "\n",
    "            if word not in cap2ids:\n",
    "                cap2ids[word] = [imageID]  # index 0 is used for placeholder\n",
    "            else:\n",
    "                if imageID  not in cap2ids[word]:\n",
    "                    cap2ids[word].append(imageID)\n",
    "\n",
    "# import random\n",
    "# for key, value in cap2ids.items():\n",
    "#     if len(value) < num_img:\n",
    "#         value.extend([0] * (num_img - len(value)))\n",
    "#         cap2ids[key] = value\n",
    "#     else:\n",
    "#         value = random.sample(value, num_img)\n",
    "#         cap2ids[key] = value\n",
    "\n",
    "# pickle.dump(cap2ids,open(cap2image_file,\"wb\"))\n",
    "\n",
    "# print(\"data process finished!\")\n",
    "# print(len(cap2ids))\n",
    "# print(total_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clean': [318556, 538480, 266366, 0, 0],\n",
       " 'decorated': [318556, 0, 0, 0, 0],\n",
       " 'bathroom': [318556, 28149, 266366, 517565, 538480],\n",
       " 'panoramic': [116100, 0, 0, 0, 0],\n",
       " 'view': [116100, 318556, 0, 0, 0],\n",
       " 'kitchen': [476220, 299675, 360334, 122802, 360306],\n",
       " 'appliance': [116100, 476220, 0, 0, 0],\n",
       " 'blue': [318556, 538480, 0, 0, 0],\n",
       " 'butterfly': [318556, 0, 0, 0, 0],\n",
       " 'themed': [318556, 0, 0, 0, 0],\n",
       " 'wall': [318556, 538480, 0, 0, 0],\n",
       " 'photo': [116100, 124567, 0, 0, 0],\n",
       " 'dining': [116100, 0, 0, 0, 0],\n",
       " 'sign': [379340, 0, 0, 0, 0],\n",
       " 'street': [379340, 385716, 31813, 0, 0],\n",
       " 'vandalized': [379340, 0, 0, 0, 0],\n",
       " 'beetle': [379340, 0, 0, 0, 0],\n",
       " 'road': [379340, 0, 0, 0, 0],\n",
       " 'border': [318556, 0, 0, 0, 0],\n",
       " 'paint': [318556, 0, 0, 0, 0],\n",
       " 'angled': [318556, 0, 0, 0, 0],\n",
       " 'beautifully': [318556, 0, 0, 0, 0],\n",
       " 'people': [134754, 18691, 302443, 0, 0],\n",
       " 'walking': [134754, 293605, 385716, 302443, 0],\n",
       " 'beach': [134754, 31813, 0, 0, 0],\n",
       " 'sink': [266366, 538480, 32275, 360306, 56972],\n",
       " 'toilet': [538480, 266366, 517565, 0, 0],\n",
       " 'white': [476220, 299675, 56972, 360334, 0],\n",
       " 'black': [476220, 28231, 72704, 25470, 0],\n",
       " 'square': [299675, 0, 0, 0, 0],\n",
       " 'tile': [299675, 161657, 0, 0, 0],\n",
       " 'floor': [299675, 503598, 0, 0, 0],\n",
       " 'repair': [299675, 0, 0, 0, 0],\n",
       " 'vanity': [32275, 0, 0, 0, 0],\n",
       " 'towel': [32275, 0, 0, 0, 0],\n",
       " 'metal': [302443, 0, 0, 0, 0],\n",
       " 'ball': [302443, 0, 0, 0, 0],\n",
       " 'sit': [302443, 18691, 0, 0, 0],\n",
       " 'sand': [302443, 0, 0, 0, 0],\n",
       " 'carrying': [134754, 385716, 0, 0, 0],\n",
       " 'surf': [134754, 0, 0, 0, 0],\n",
       " 'board': [134754, 0, 0, 0, 0],\n",
       " 'brown': [25470, 0, 0, 0, 0],\n",
       " 'backsplash': [25470, 321194, 0, 0, 0],\n",
       " 'grey': [25470, 0, 0, 0, 0],\n",
       " 'counter': [25470, 360306, 321194, 389006, 0],\n",
       " 'surfer': [513461, 31813, 0, 0, 0],\n",
       " 'woman': [513461, 226658, 293605, 47093, 0],\n",
       " 'child': [513461, 213532, 0, 0, 0],\n",
       " 'walk': [513461, 285579, 0, 0, 0],\n",
       " 'dim': [18691, 0, 0, 0, 0],\n",
       " 'transportation': [18691, 0, 0, 0, 0],\n",
       " 'protected': [285579, 0, 0, 0, 0],\n",
       " 'rain': [285579, 0, 0, 0, 0],\n",
       " 'umbrella': [285579, 0, 0, 0, 0],\n",
       " 'ha': [266366, 44816, 299675, 56972, 0],\n",
       " 'preparing': [226658, 0, 0, 0, 0],\n",
       " 'food': [226658, 503598, 0, 0, 0],\n",
       " 'table': [226658, 543882, 0, 0, 0],\n",
       " 'light': [299675, 321194, 385716, 0, 0],\n",
       " 'cat': [124567, 72704, 0, 0, 0],\n",
       " 'stuck': [124567, 0, 0, 0, 0],\n",
       " 'car': [124567, 28231, 101891, 24091, 0],\n",
       " 'window': [124567, 44816, 0, 0, 0],\n",
       " 'bicycle': [479495, 293605, 520049, 101891, 90359],\n",
       " 'shop': [293605, 0, 0, 0, 0],\n",
       " 'green': [321194, 0, 0, 0, 0],\n",
       " 'tiled': [321194, 538480, 0, 0, 0],\n",
       " 'highlighted': [321194, 0, 0, 0, 0],\n",
       " 'parked': [479495, 0, 0, 0, 0],\n",
       " 'bench': [479495, 174028, 90359, 0, 0],\n",
       " 'night': [479495, 38682, 0, 0, 0],\n",
       " 'horse': [539984, 0, 0, 0, 0],\n",
       " 'grazing': [539984, 0, 0, 0, 0],\n",
       " 'grass': [539984, 0, 0, 0, 0],\n",
       " 'house': [539984, 0, 0, 0, 0],\n",
       " 'riding': [28231, 31813, 38682, 0, 0],\n",
       " 'bike': [28231, 31813, 90359, 0, 0],\n",
       " 'pedestal': [538480, 0, 0, 0, 0],\n",
       " 'located': [538480, 0, 0, 0, 0],\n",
       " 'lit': [538480, 0, 0, 0, 0],\n",
       " 'game': [350235, 0, 0, 0, 0],\n",
       " 'shirt': [350235, 0, 0, 0, 0],\n",
       " 'bathtub': [314265, 0, 0, 0, 0],\n",
       " 'shower': [314265, 517565, 0, 0, 0],\n",
       " 'mirror': [314265, 28149, 0, 0, 0],\n",
       " 'cabinet': [314265, 299675, 0, 0, 0],\n",
       " 'countertop': [389006, 122802, 25470, 0, 0],\n",
       " 'includes': [389006, 0, 0, 0, 0],\n",
       " 'apple': [389006, 0, 0, 0, 0],\n",
       " 'phone': [389006, 47093, 0, 0, 0],\n",
       " 'teenager': [134754, 0, 0, 0, 0],\n",
       " 'sanded': [134754, 0, 0, 0, 0],\n",
       " 'surfboard': [134754, 0, 0, 0, 0],\n",
       " 'indoor': [538480, 0, 0, 0, 0],\n",
       " 'lighting': [538480, 0, 0, 0, 0],\n",
       " 'closeup': [465049, 0, 0, 0, 0],\n",
       " 'hydrant': [465049, 0, 0, 0, 0],\n",
       " 'including': [465049, 0, 0, 0, 0],\n",
       " 'chain': [465049, 0, 0, 0, 0],\n",
       " 'standing': [360334, 122802, 360306, 0, 0],\n",
       " 'arm': [360334, 0, 0, 0, 0],\n",
       " 'crossed': [360334, 0, 0, 0, 0],\n",
       " 'purple': [524679, 0, 0, 0, 0],\n",
       " 'dressed': [524679, 0, 0, 0, 0],\n",
       " 'nun': [524679, 0, 0, 0, 0],\n",
       " 'tall': [524679, 0, 0, 0, 0],\n",
       " 'herb': [279672, 0, 0, 0, 0],\n",
       " 'toaster': [279672, 0, 0, 0, 0],\n",
       " 'oven': [279672, 0, 0, 0, 0],\n",
       " 'lady': [385716, 577876, 0, 0, 0],\n",
       " 'purse': [385716, 0, 0, 0, 0],\n",
       " 'brightly': [44816, 0, 0, 0, 0],\n",
       " 'colored': [44816, 0, 0, 0, 0],\n",
       " 'wide': [116100, 0, 0, 0, 0],\n",
       " 'angle': [116100, 0, 0, 0, 0],\n",
       " 'silver': [302443, 0, 0, 0, 0],\n",
       " 'ground': [302443, 0, 0, 0, 0],\n",
       " 'illuminated': [360306, 321194, 0, 0, 0],\n",
       " 'sunlight': [360306, 0, 0, 0, 0],\n",
       " 'granite': [122802, 0, 0, 0, 0],\n",
       " 'skinny': [539984, 0, 0, 0, 0],\n",
       " 'field': [539984, 0, 0, 0, 0],\n",
       " 'person': [28231, 124567, 0, 0, 0],\n",
       " 'seagull': [515040, 0, 0, 0, 0],\n",
       " 'flying': [515040, 0, 0, 0, 0],\n",
       " 'parking': [515040, 0, 0, 0, 0],\n",
       " 'lot': [515040, 0, 0, 0, 0],\n",
       " 'door': [299675, 0, 0, 0, 0],\n",
       " 'dishwasher': [299675, 0, 0, 0, 0],\n",
       " 'refrigerator': [299675, 0, 0, 0, 0],\n",
       " 'modern': [161657, 266366, 0, 0, 0],\n",
       " 'glass': [161657, 0, 0, 0, 0],\n",
       " 'piece': [161657, 0, 0, 0, 0],\n",
       " 'demonstration': [266366, 0, 0, 0, 0],\n",
       " 'maintained': [266366, 0, 0, 0, 0],\n",
       " 'hotel': [266366, 0, 0, 0, 0],\n",
       " 'angry': [72704, 0, 0, 0, 0],\n",
       " 'sitting': [72704, 174028, 0, 0, 0],\n",
       " 'mediocre': [266366, 0, 0, 0, 0],\n",
       " 'motel': [266366, 0, 0, 0, 0],\n",
       " 'nice': [266366, 0, 0, 0, 0],\n",
       " 'hood': [321194, 0, 0, 0, 0],\n",
       " 'city': [385716, 0, 0, 0, 0],\n",
       " 'sidewalk': [385716, 0, 0, 0, 0],\n",
       " 'lamp': [385716, 0, 0, 0, 0],\n",
       " 'post': [385716, 0, 0, 0, 0],\n",
       " 'public': [257263, 0, 0, 0, 0],\n",
       " 'restroom': [257263, 32275, 0, 0, 0],\n",
       " 'photographed': [257263, 0, 0, 0, 0],\n",
       " 'sepia': [257263, 0, 0, 0, 0],\n",
       " 'styled': [520049, 0, 0, 0, 0],\n",
       " 'appears': [520049, 0, 0, 0, 0],\n",
       " 'gate': [520049, 0, 0, 0, 0],\n",
       " 'bridge': [520049, 0, 0, 0, 0],\n",
       " 'peeking': [124567, 0, 0, 0, 0],\n",
       " 'rolled': [124567, 0, 0, 0, 0],\n",
       " 'pet': [503598, 0, 0, 0, 0],\n",
       " 'boy': [230843, 0, 0, 0, 0],\n",
       " 'surfing': [230843, 0, 0, 0, 0],\n",
       " 'wave': [230843, 0, 0, 0, 0],\n",
       " 'covered': [231029, 543882, 0, 0, 0],\n",
       " 'brass': [231029, 0, 0, 0, 0],\n",
       " 'pot': [231029, 0, 0, 0, 0],\n",
       " 'pan': [231029, 0, 0, 0, 0],\n",
       " 'shaving': [174028, 0, 0, 0, 0],\n",
       " 'wooden': [174028, 517565, 0, 0, 0],\n",
       " 'sky': [480489, 0, 0, 0, 0],\n",
       " 'colorful': [480489, 0, 0, 0, 0],\n",
       " 'kite': [480489, 0, 0, 0, 0],\n",
       " 'mountain': [480489, 374873, 0, 0, 0],\n",
       " 'ride': [520049, 31813, 0, 0, 0],\n",
       " 'river': [520049, 0, 0, 0, 0],\n",
       " 'stand': [385716, 0, 0, 0, 0],\n",
       " 'cupboard': [56972, 0, 0, 0, 0],\n",
       " 'raft': [187042, 0, 0, 0, 0],\n",
       " 'atop': [187042, 0, 0, 0, 0],\n",
       " 'boat': [187042, 0, 0, 0, 0],\n",
       " 'water': [187042, 0, 0, 0, 0],\n",
       " 'trash': [101891, 0, 0, 0, 0],\n",
       " 'garage': [101891, 0, 0, 0, 0],\n",
       " 'short': [360306, 0, 0, 0, 0],\n",
       " 'seat': [124567, 517565, 0, 0, 0],\n",
       " 'jumping': [90359, 0, 0, 0, 0],\n",
       " 'folded': [360334, 0, 0, 0, 0],\n",
       " 'balancing': [90359, 0, 0, 0, 0],\n",
       " 'image': [213532, 0, 0, 0, 0],\n",
       " 'paying': [213532, 0, 0, 0, 0],\n",
       " 'attention': [213532, 0, 0, 0, 0],\n",
       " 'lined': [302443, 0, 0, 0, 0],\n",
       " 'background': [302443, 0, 0, 0, 0],\n",
       " 'compact': [24091, 0, 0, 0, 0],\n",
       " 'mounted': [24091, 0, 0, 0, 0],\n",
       " 'roof': [24091, 0, 0, 0, 0],\n",
       " 'crisp': [372427, 0, 0, 0, 0],\n",
       " 'neutral': [372427, 0, 0, 0, 0],\n",
       " 'embellished': [372427, 0, 0, 0, 0],\n",
       " 'treatment': [372427, 0, 0, 0, 0],\n",
       " 'stainless': [376047, 0, 0, 0, 0],\n",
       " 'steel': [376047, 0, 0, 0, 0],\n",
       " 'checkered': [376047, 0, 0, 0, 0],\n",
       " 'pattern': [376047, 0, 0, 0, 0],\n",
       " 'talking': [577876, 47093, 0, 0, 0],\n",
       " 'portrait': [577876, 0, 0, 0, 0],\n",
       " 'fancy': [577876, 0, 0, 0, 0],\n",
       " 'cell': [47093, 0, 0, 0, 0],\n",
       " 'accessory': [266366, 0, 0, 0, 0],\n",
       " 'set': [266366, 0, 0, 0, 0],\n",
       " 'snowy': [374873, 0, 0, 0, 0],\n",
       " 'ski': [374873, 0, 0, 0, 0],\n",
       " 'washcloth': [32275, 0, 0, 0, 0],\n",
       " 'laid': [32275, 0, 0, 0, 0],\n",
       " 'stuffed': [360053, 0, 0, 0, 0],\n",
       " 'animal': [360053, 0, 0, 0, 0],\n",
       " 'laying': [360053, 0, 0, 0, 0],\n",
       " 'bed': [360053, 0, 0, 0, 0],\n",
       " 'blacksplash': [25470, 0, 0, 0, 0],\n",
       " 'sits': [517565, 0, 0, 0, 0],\n",
       " 'plate': [543882, 0, 0, 0, 0],\n",
       " 'vegetable': [543882, 0, 0, 0, 0],\n",
       " 'couple': [134754, 0, 0, 0, 0],\n",
       " 'toilette': [517565, 0, 0, 0, 0],\n",
       " 'picture': [38682, 0, 0, 0, 0],\n",
       " 'hour': [539984, 0, 0, 0, 0],\n",
       " 'eating': [539984, 0, 0, 0, 0],\n",
       " 'blurry': [28231, 0, 0, 0, 0],\n",
       " 'rider': [28231, 0, 0, 0, 0],\n",
       " 'zoom': [28231, 0, 0, 0, 0],\n",
       " 'mercedes': [28231, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap2ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
